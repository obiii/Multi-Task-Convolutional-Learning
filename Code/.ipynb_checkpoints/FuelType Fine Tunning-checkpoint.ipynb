{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = '../FuelTypeData/train/'\n",
    "testPath = '../FuelTypeData/test/'\n",
    "valPath = '../FuelTypeData/vald'\n",
    "BATCH_SIZE = 128\n",
    "PFR_NUM_CLASS = 10\n",
    "FUEL_TYPE_NUM_CLASS = 5\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTrain = len(list(paths.list_images(trainPath)))\n",
    "totalVal = len(list(paths.list_images(testPath)))\n",
    "totalTest = len(list(paths.list_images(valPath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(H, N, plotPath):\n",
    "    # construct a plot that plots and saves the training history\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator('''\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"''')\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator()\n",
    "# define the ImageNet mean subtraction (in RGB order) and set the\n",
    "# the mean subtraction value for each of the data augmentation\n",
    "# objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8557 images belonging to 5 classes.\n",
      "Found 1063 images belonging to 5 classes.\n",
      "Found 1063 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# initialize the training generator\n",
    "img_size = 224\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    trainPath,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE)\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "    valPath,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE)\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "    testPath,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG16 network, ensuring the head FC layer sets are left off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(img_size, img_size, 3)))\n",
    "# construct the head of the model that will be placed on top of the the base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseModel =  pickle.load(open('../Models/VGG16.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(FUEL_TYPE_NUM_CLASS, activation=\"softmax\")(headModel)\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as tfback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0', '/device:GPU:1']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfback._get_available_gpus = _get_available_gpus\n",
    "tfback._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
       " LogicalDevice(name='/device:GPU:0', device_type='GPU'),\n",
       " LogicalDevice(name='/device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_gpu_model(model,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "Epoch 1/50\n",
      "267/267 [==============================] - 112s 420ms/step - loss: 4.1701 - accuracy: 0.7391 - val_loss: 0.0058 - val_accuracy: 0.8902\n",
      "Epoch 2/50\n",
      "267/267 [==============================] - 106s 396ms/step - loss: 0.3561 - accuracy: 0.8777 - val_loss: 0.0053 - val_accuracy: 0.9098\n",
      "Epoch 3/50\n",
      "267/267 [==============================] - 104s 388ms/step - loss: 0.2594 - accuracy: 0.9046 - val_loss: 0.0299 - val_accuracy: 0.9350\n",
      "Epoch 4/50\n",
      "267/267 [==============================] - 104s 388ms/step - loss: 0.2072 - accuracy: 0.9191 - val_loss: 0.2860 - val_accuracy: 0.9350\n",
      "Epoch 5/50\n",
      "267/267 [==============================] - 104s 391ms/step - loss: 0.1879 - accuracy: 0.9239 - val_loss: 4.4361e-04 - val_accuracy: 0.9437\n",
      "Epoch 6/50\n",
      "267/267 [==============================] - 105s 392ms/step - loss: 0.1513 - accuracy: 0.9397 - val_loss: 0.0054 - val_accuracy: 0.9457\n",
      "Epoch 7/50\n",
      "267/267 [==============================] - 104s 388ms/step - loss: 0.1431 - accuracy: 0.9390 - val_loss: 0.1230 - val_accuracy: 0.9428\n",
      "Epoch 8/50\n",
      "267/267 [==============================] - 104s 391ms/step - loss: 0.1412 - accuracy: 0.9369 - val_loss: 0.0037 - val_accuracy: 0.9437\n",
      "Epoch 9/50\n",
      "267/267 [==============================] - 104s 388ms/step - loss: 0.1322 - accuracy: 0.9347 - val_loss: 5.0886e-04 - val_accuracy: 0.9273\n",
      "Epoch 10/50\n",
      "267/267 [==============================] - 104s 389ms/step - loss: 0.1207 - accuracy: 0.9472 - val_loss: 2.5555e-06 - val_accuracy: 0.9437\n",
      "Epoch 11/50\n",
      "267/267 [==============================] - 106s 396ms/step - loss: 0.1134 - accuracy: 0.9526 - val_loss: 8.1568e-04 - val_accuracy: 0.9408\n",
      "Epoch 12/50\n",
      "267/267 [==============================] - 104s 390ms/step - loss: 0.0971 - accuracy: 0.9520 - val_loss: 4.2228e-05 - val_accuracy: 0.9418\n",
      "Epoch 13/50\n",
      "267/267 [==============================] - 103s 388ms/step - loss: 0.1011 - accuracy: 0.9544 - val_loss: 0.0951 - val_accuracy: 0.9505\n",
      "Epoch 14/50\n",
      "267/267 [==============================] - 104s 388ms/step - loss: 0.0998 - accuracy: 0.9596 - val_loss: 2.3790e-04 - val_accuracy: 0.9224\n",
      "Epoch 15/50\n",
      "267/267 [==============================] - 104s 391ms/step - loss: 0.1095 - accuracy: 0.9512 - val_loss: 0.1229 - val_accuracy: 0.9302\n",
      "Epoch 16/50\n",
      "267/267 [==============================] - 104s 390ms/step - loss: 0.0853 - accuracy: 0.9589 - val_loss: 0.1853 - val_accuracy: 0.9263\n",
      "Epoch 17/50\n",
      "267/267 [==============================] - 105s 394ms/step - loss: 0.1135 - accuracy: 0.9503 - val_loss: 0.0018 - val_accuracy: 0.9418\n",
      "Epoch 18/50\n",
      "267/267 [==============================] - 106s 398ms/step - loss: 0.0739 - accuracy: 0.9695 - val_loss: 0.0077 - val_accuracy: 0.9447\n",
      "Epoch 19/50\n",
      "267/267 [==============================] - 104s 390ms/step - loss: 0.1021 - accuracy: 0.9559 - val_loss: 0.5500 - val_accuracy: 0.9593\n",
      "Epoch 20/50\n",
      "267/267 [==============================] - 104s 388ms/step - loss: 0.0763 - accuracy: 0.9703 - val_loss: 0.2379 - val_accuracy: 0.9544\n",
      "Epoch 21/50\n",
      "267/267 [==============================] - 104s 389ms/step - loss: 0.0899 - accuracy: 0.9598 - val_loss: 0.0455 - val_accuracy: 0.9612\n",
      "Epoch 22/50\n",
      "267/267 [==============================] - 105s 395ms/step - loss: 0.0727 - accuracy: 0.9686 - val_loss: 1.8787 - val_accuracy: 0.9195\n",
      "Epoch 23/50\n",
      "267/267 [==============================] - 106s 396ms/step - loss: 0.1057 - accuracy: 0.9555 - val_loss: 0.6849 - val_accuracy: 0.9544\n",
      "Epoch 24/50\n",
      "267/267 [==============================] - 104s 391ms/step - loss: 0.0725 - accuracy: 0.9650 - val_loss: 0.0020 - val_accuracy: 0.9622\n",
      "Epoch 25/50\n",
      "267/267 [==============================] - 104s 390ms/step - loss: 0.0806 - accuracy: 0.9704 - val_loss: 0.0415 - val_accuracy: 0.9496\n",
      "Epoch 26/50\n",
      "267/267 [==============================] - 104s 388ms/step - loss: 0.0766 - accuracy: 0.9674 - val_loss: 0.1783 - val_accuracy: 0.9340\n",
      "Epoch 27/50\n",
      "267/267 [==============================] - 104s 388ms/step - loss: 0.0564 - accuracy: 0.9796 - val_loss: 0.1990 - val_accuracy: 0.9505\n",
      "Epoch 28/50\n",
      "267/267 [==============================] - 104s 388ms/step - loss: 0.0789 - accuracy: 0.9665 - val_loss: 0.0163 - val_accuracy: 0.9680\n",
      "Epoch 29/50\n",
      "267/267 [==============================] - 105s 393ms/step - loss: 0.0639 - accuracy: 0.9764 - val_loss: 0.0760 - val_accuracy: 0.9593\n",
      "Epoch 30/50\n",
      "267/267 [==============================] - 104s 391ms/step - loss: 0.0657 - accuracy: 0.9740 - val_loss: 4.9176e-05 - val_accuracy: 0.9602\n",
      "Epoch 31/50\n",
      "267/267 [==============================] - 104s 388ms/step - loss: 0.0553 - accuracy: 0.9748 - val_loss: 3.0535e-04 - val_accuracy: 0.9331\n",
      "Epoch 32/50\n",
      "267/267 [==============================] - 105s 392ms/step - loss: 0.0722 - accuracy: 0.9707 - val_loss: 0.0029 - val_accuracy: 0.9544\n",
      "Epoch 33/50\n",
      "267/267 [==============================] - 104s 389ms/step - loss: 0.0544 - accuracy: 0.9822 - val_loss: 0.0220 - val_accuracy: 0.9467\n",
      "Epoch 34/50\n",
      "267/267 [==============================] - 103s 387ms/step - loss: 0.0509 - accuracy: 0.9788 - val_loss: 6.4882e-06 - val_accuracy: 0.9437\n",
      "Epoch 35/50\n",
      "267/267 [==============================] - 104s 389ms/step - loss: 0.0707 - accuracy: 0.9697 - val_loss: 4.0122e-05 - val_accuracy: 0.9612\n",
      "Epoch 36/50\n",
      "267/267 [==============================] - 108s 404ms/step - loss: 0.0563 - accuracy: 0.9762 - val_loss: 8.4004e-05 - val_accuracy: 0.9593\n",
      "Epoch 37/50\n",
      "267/267 [==============================] - 104s 390ms/step - loss: 0.0503 - accuracy: 0.9796 - val_loss: 2.0489e-05 - val_accuracy: 0.9447\n",
      "Epoch 38/50\n",
      "267/267 [==============================] - 107s 400ms/step - loss: 0.0603 - accuracy: 0.9767 - val_loss: 0.3054 - val_accuracy: 0.9340\n",
      "Epoch 39/50\n",
      "267/267 [==============================] - 107s 401ms/step - loss: 0.0653 - accuracy: 0.9740 - val_loss: 2.7567e-07 - val_accuracy: 0.9476\n",
      "Epoch 40/50\n",
      "267/267 [==============================] - 109s 407ms/step - loss: 0.0457 - accuracy: 0.9820 - val_loss: 6.0096e-04 - val_accuracy: 0.9631\n",
      "Epoch 41/50\n",
      "267/267 [==============================] - 106s 398ms/step - loss: 0.0510 - accuracy: 0.9824 - val_loss: 1.1764e-04 - val_accuracy: 0.9350\n",
      "Epoch 42/50\n",
      "267/267 [==============================] - 104s 391ms/step - loss: 0.0442 - accuracy: 0.9823 - val_loss: 1.6913e-06 - val_accuracy: 0.9534\n",
      "Epoch 43/50\n",
      "267/267 [==============================] - 106s 397ms/step - loss: 0.0536 - accuracy: 0.9784 - val_loss: 1.8999e-07 - val_accuracy: 0.9602\n",
      "Epoch 44/50\n",
      "267/267 [==============================] - 105s 394ms/step - loss: 0.0530 - accuracy: 0.9777 - val_loss: 2.6077e-08 - val_accuracy: 0.9418\n",
      "Epoch 45/50\n",
      "267/267 [==============================] - 104s 391ms/step - loss: 0.0379 - accuracy: 0.9857 - val_loss: 2.7686e-05 - val_accuracy: 0.9486\n",
      "Epoch 46/50\n",
      "267/267 [==============================] - 105s 392ms/step - loss: 0.0562 - accuracy: 0.9771 - val_loss: 2.6970e-06 - val_accuracy: 0.9564\n",
      "Epoch 47/50\n",
      "267/267 [==============================] - 105s 392ms/step - loss: 0.0452 - accuracy: 0.9802 - val_loss: 0.1063 - val_accuracy: 0.9263\n",
      "Epoch 48/50\n",
      "267/267 [==============================] - 105s 395ms/step - loss: 0.0634 - accuracy: 0.9690 - val_loss: 1.5701e-05 - val_accuracy: 0.9428\n",
      "Epoch 49/50\n",
      "267/267 [==============================] - 105s 393ms/step - loss: 0.0416 - accuracy: 0.9853 - val_loss: 0.2044 - val_accuracy: 0.9486\n",
      "Epoch 50/50\n",
      "267/267 [==============================] - 105s 392ms/step - loss: 0.0374 - accuracy: 0.9825 - val_loss: 0.0264 - val_accuracy: 0.9360\n"
     ]
    }
   ],
   "source": [
    "# compile our model (this needs to be done after our setting our layers to being non-trainable\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "# train the head of the network for a few epochs (all other layers\n",
    "# are frozen) -- this will allow the new FC layers to start to become\n",
    "#initialized with actual \"learned\" values versus pure random\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit_generator(\n",
    "    trainGen,\n",
    "    steps_per_epoch=totalTrain // BATCH_SIZE,\n",
    "    validation_data=valGen,\n",
    "    validation_steps=totalVal // BATCH_SIZE,\n",
    "    epochs=EPOCHS)\n",
    "# reset the testing generator and evaluate the network after\n",
    "# fine-tuning just the network head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating after fine-tuning network head...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating after fine-tuning network head...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "    steps=(totalTest // BATCH_SIZE) + 1)\n",
    "predIdxsClasses = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(testGen.classes, predIdxsClasses,\n",
    "    target_names=testGen.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20H280NG', 'Ethlyne', 'F1', 'F2', 'NG']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs = testGen.class_indices.keys()\n",
    "FTLabels = []\n",
    "for lab in labs:\n",
    "    FTLabels.append(lab)\n",
    "FTLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1-3</th>\n",
       "      <th>10-12</th>\n",
       "      <th>13-15</th>\n",
       "      <th>20-25</th>\n",
       "      <th>30-40</th>\n",
       "      <th>4-5</th>\n",
       "      <th>41-56</th>\n",
       "      <th>6-9</th>\n",
       "      <th>60+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1-3</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30-40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4-5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41-56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6-9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60+</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1-3  10-12  13-15  20-25  30-40  4-5  41-56  6-9  60+\n",
       "0      575    0      0      0      0      0    1      0    0    0\n",
       "1-3     10   32      0      0      1      0    7      0    0    0\n",
       "10-12    0    0     94      3      0      0    0      0    8    0\n",
       "13-15    1    0      3     22      0      3    0      0    0    0\n",
       "20-25    1    0      0      3     33      4    0      0    0    0\n",
       "30-40    0    0      0      0      0     43    0      0    0    3\n",
       "4-5      5    2      0      0      0      0   58      0    1    0\n",
       "41-56    0    0      0      0      0      3    0     11    0    0\n",
       "6-9      2    2      3      0      0      0   29      0   64    1\n",
       "60+      0    0      0      0      0      1    0      0    0   24"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(testGen.classes, predIdxsClasses)\n",
    "cm = pd.DataFrame(cm)\n",
    "cm.columns = FTLabels\n",
    "cm.index = FTLabels\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_PLOT_PATH = '../Models/FuelTypeModel/train.png'\n",
    "plot_training(H, EPOCHS, WARMUP_PLOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('../Models/FuelTypeModel/FTModel.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
