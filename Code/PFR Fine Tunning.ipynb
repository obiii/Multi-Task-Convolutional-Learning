{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = '../PFR_Data/train/'\n",
    "testPath = '../PFR_Data/test/'\n",
    "valPath = '../PFR_Data/vald'\n",
    "BATCH_SIZE = 128\n",
    "PFR_NUM_CLASS = 10\n",
    "FUEL_TYPE_NUM_CLASS = 5\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTrain = len(list(paths.list_images(trainPath)))\n",
    "totalVal = len(list(paths.list_images(valPath)))\n",
    "totalTest = len(list(paths.list_images(testPath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(H, N, plotPath):\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator('''\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"''')\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator()\n",
    "# define the ImageNet mean subtraction (in RGB order) and set the\n",
    "# the mean subtraction value for each of the data augmentation\n",
    "# objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8555 images belonging to 10 classes.\n",
      "Found 1053 images belonging to 10 classes.\n",
      "Found 1053 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# initialize the training generator\n",
    "img_size = 224\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    trainPath,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE)\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "    valPath,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE)\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "    testPath,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG16 network, ensuring the head FC layer sets are left off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(img_size, img_size, 3)))\n",
    "# construct the head of the model that will be placed on top of the the base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseModel =  pickle.load(open('../Models/VGG16.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(PFR_NUM_CLASS, activation=\"softmax\")(headModel)\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(trainGen.classes), \n",
    "                trainGen.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18517316, 2.06642512, 1.00410798, 3.52057613, 2.4869186 ,\n",
       "       2.27526596, 1.57261029, 6.68359375, 1.04202192, 4.01643192])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "Epoch 1/150\n",
      "66/66 [==============================] - 109s 2s/step - loss: 7.5586 - accuracy: 0.4907 - val_loss: 1.1135 - val_accuracy: 0.6963\n",
      "Epoch 2/150\n",
      "66/66 [==============================] - 86s 1s/step - loss: 1.1907 - accuracy: 0.6077 - val_loss: 2.0509 - val_accuracy: 0.7589\n",
      "Epoch 3/150\n",
      "66/66 [==============================] - 87s 1s/step - loss: 0.9895 - accuracy: 0.6477 - val_loss: 1.7461 - val_accuracy: 0.7697\n",
      "Epoch 4/150\n",
      "66/66 [==============================] - 90s 1s/step - loss: 0.8446 - accuracy: 0.6931 - val_loss: 0.6759 - val_accuracy: 0.7870\n",
      "Epoch 5/150\n",
      "66/66 [==============================] - 94s 1s/step - loss: 0.7427 - accuracy: 0.7395 - val_loss: 0.0276 - val_accuracy: 0.7481\n",
      "Epoch 6/150\n",
      "66/66 [==============================] - 96s 1s/step - loss: 0.7869 - accuracy: 0.7039 - val_loss: 0.0536 - val_accuracy: 0.7416\n",
      "Epoch 7/150\n",
      "66/66 [==============================] - 86s 1s/step - loss: 0.5979 - accuracy: 0.7754 - val_loss: 5.4435e-04 - val_accuracy: 0.7481\n",
      "Epoch 8/150\n",
      "66/66 [==============================] - 79s 1s/step - loss: 0.6532 - accuracy: 0.7494 - val_loss: 0.0356 - val_accuracy: 0.7708\n",
      "Epoch 9/150\n",
      "66/66 [==============================] - 85s 1s/step - loss: 0.5124 - accuracy: 0.8057 - val_loss: 0.3320 - val_accuracy: 0.7762\n",
      "Epoch 10/150\n",
      "66/66 [==============================] - 85s 1s/step - loss: 0.5575 - accuracy: 0.7710 - val_loss: 1.0002 - val_accuracy: 0.8018\n",
      "Epoch 11/150\n",
      "66/66 [==============================] - 88s 1s/step - loss: 0.5843 - accuracy: 0.7701 - val_loss: 1.2639 - val_accuracy: 0.8303\n",
      "Epoch 12/150\n",
      "66/66 [==============================] - 84s 1s/step - loss: 0.5131 - accuracy: 0.7994 - val_loss: 1.1042 - val_accuracy: 0.8627\n",
      "Epoch 13/150\n",
      "66/66 [==============================] - 81s 1s/step - loss: 0.4651 - accuracy: 0.8131 - val_loss: 0.3989 - val_accuracy: 0.8703\n",
      "Epoch 14/150\n",
      "66/66 [==============================] - 87s 1s/step - loss: 0.4959 - accuracy: 0.8022 - val_loss: 0.0340 - val_accuracy: 0.8195\n",
      "Epoch 15/150\n",
      "66/66 [==============================] - 79s 1s/step - loss: 0.4436 - accuracy: 0.8180 - val_loss: 0.0203 - val_accuracy: 0.8086\n",
      "Epoch 16/150\n",
      "66/66 [==============================] - 74s 1s/step - loss: 0.3997 - accuracy: 0.8425 - val_loss: 2.1055e-04 - val_accuracy: 0.8076\n",
      "Epoch 17/150\n",
      "66/66 [==============================] - 76s 1s/step - loss: 0.3999 - accuracy: 0.8370 - val_loss: 0.0049 - val_accuracy: 0.8270\n",
      "Epoch 18/150\n",
      "66/66 [==============================] - 82s 1s/step - loss: 0.4437 - accuracy: 0.8175 - val_loss: 0.3724 - val_accuracy: 0.8519\n",
      "Epoch 19/150\n",
      "66/66 [==============================] - 82s 1s/step - loss: 0.3166 - accuracy: 0.8784 - val_loss: 0.7066 - val_accuracy: 0.8506\n",
      "Epoch 20/150\n",
      "66/66 [==============================] - 80s 1s/step - loss: 0.3814 - accuracy: 0.8449 - val_loss: 0.9054 - val_accuracy: 0.8778\n",
      "Epoch 21/150\n",
      "66/66 [==============================] - 74s 1s/step - loss: 0.3641 - accuracy: 0.8498 - val_loss: 0.9783 - val_accuracy: 0.8995\n",
      "Epoch 22/150\n",
      "66/66 [==============================] - 83s 1s/step - loss: 0.3479 - accuracy: 0.8596 - val_loss: 0.4540 - val_accuracy: 0.8778\n",
      "Epoch 23/150\n",
      "66/66 [==============================] - 82s 1s/step - loss: 0.3057 - accuracy: 0.8769 - val_loss: 0.0366 - val_accuracy: 0.8789\n",
      "Epoch 24/150\n",
      "66/66 [==============================] - 79s 1s/step - loss: 0.2982 - accuracy: 0.8788 - val_loss: 0.0054 - val_accuracy: 0.8281\n",
      "Epoch 25/150\n",
      "66/66 [==============================] - 76s 1s/step - loss: 0.3238 - accuracy: 0.8678 - val_loss: 1.1855e-04 - val_accuracy: 0.8378\n",
      "Epoch 26/150\n",
      "66/66 [==============================] - 79s 1s/step - loss: 0.2736 - accuracy: 0.8867 - val_loss: 0.0088 - val_accuracy: 0.8584\n",
      "Epoch 27/150\n",
      "66/66 [==============================] - 76s 1s/step - loss: 0.3128 - accuracy: 0.8697 - val_loss: 0.1088 - val_accuracy: 0.8335\n",
      "Epoch 28/150\n",
      "66/66 [==============================] - 77s 1s/step - loss: 0.2661 - accuracy: 0.8934 - val_loss: 0.6572 - val_accuracy: 0.8672\n",
      "Epoch 29/150\n",
      "66/66 [==============================] - 79s 1s/step - loss: 0.2958 - accuracy: 0.8786 - val_loss: 0.6162 - val_accuracy: 0.9016\n",
      "Epoch 30/150\n",
      "66/66 [==============================] - 74s 1s/step - loss: 0.2963 - accuracy: 0.8777 - val_loss: 0.7859 - val_accuracy: 0.9124\n",
      "Epoch 31/150\n",
      "66/66 [==============================] - 79s 1s/step - loss: 0.2560 - accuracy: 0.8943 - val_loss: 0.5012 - val_accuracy: 0.8962\n",
      "Epoch 32/150\n",
      "66/66 [==============================] - 76s 1s/step - loss: 0.1897 - accuracy: 0.9253 - val_loss: 0.0336 - val_accuracy: 0.8789\n",
      "Epoch 33/150\n",
      "66/66 [==============================] - 83s 1s/step - loss: 0.2933 - accuracy: 0.8727 - val_loss: 5.4882e-04 - val_accuracy: 0.8627\n",
      "Epoch 34/150\n",
      "66/66 [==============================] - 83s 1s/step - loss: 0.2483 - accuracy: 0.9032 - val_loss: 8.3860e-05 - val_accuracy: 0.8757\n",
      "Epoch 35/150\n",
      "66/66 [==============================] - 72s 1s/step - loss: 0.2234 - accuracy: 0.9096 - val_loss: 0.0065 - val_accuracy: 0.8595\n",
      "Epoch 36/150\n",
      "66/66 [==============================] - 75s 1s/step - loss: 0.2271 - accuracy: 0.9117 - val_loss: 0.2217 - val_accuracy: 0.8508\n",
      "Epoch 37/150\n",
      "66/66 [==============================] - 87s 1s/step - loss: 0.2653 - accuracy: 0.8934 - val_loss: 0.6095 - val_accuracy: 0.8770\n",
      "Epoch 38/150\n",
      "66/66 [==============================] - 93s 1s/step - loss: 0.2148 - accuracy: 0.9125 - val_loss: 0.8837 - val_accuracy: 0.8930\n",
      "Epoch 39/150\n",
      "66/66 [==============================] - 94s 1s/step - loss: 0.2273 - accuracy: 0.9082 - val_loss: 0.7997 - val_accuracy: 0.8941\n",
      "Epoch 40/150\n",
      "66/66 [==============================] - 76s 1s/step - loss: 0.1978 - accuracy: 0.9248 - val_loss: 0.4186 - val_accuracy: 0.9168\n",
      "Epoch 41/150\n",
      "66/66 [==============================] - 83s 1s/step - loss: 0.2203 - accuracy: 0.9054 - val_loss: 0.0254 - val_accuracy: 0.8973\n",
      "Epoch 42/150\n",
      "66/66 [==============================] - 88s 1s/step - loss: 0.2068 - accuracy: 0.9164 - val_loss: 4.2041e-04 - val_accuracy: 0.8670\n",
      "Epoch 43/150\n",
      "66/66 [==============================] - 81s 1s/step - loss: 0.2071 - accuracy: 0.9157 - val_loss: 1.3240e-05 - val_accuracy: 0.8703\n",
      "Epoch 44/150\n",
      "66/66 [==============================] - 81s 1s/step - loss: 0.1877 - accuracy: 0.9240 - val_loss: 0.0013 - val_accuracy: 0.8605\n",
      "Epoch 45/150\n",
      "66/66 [==============================] - 85s 1s/step - loss: 0.2188 - accuracy: 0.9068 - val_loss: 0.0817 - val_accuracy: 0.8768\n",
      "Epoch 46/150\n",
      "66/66 [==============================] - 79s 1s/step - loss: 0.1727 - accuracy: 0.9279 - val_loss: 0.5608 - val_accuracy: 0.8984\n",
      "Epoch 47/150\n",
      "66/66 [==============================] - 86s 1s/step - loss: 0.1829 - accuracy: 0.9263 - val_loss: 0.7722 - val_accuracy: 0.8930\n",
      "Epoch 48/150\n",
      "66/66 [==============================] - 75s 1s/step - loss: 0.1849 - accuracy: 0.9256 - val_loss: 0.8388 - val_accuracy: 0.9114\n",
      "Epoch 49/150\n",
      "66/66 [==============================] - 72s 1s/step - loss: 0.1725 - accuracy: 0.9320 - val_loss: 0.2314 - val_accuracy: 0.8973\n",
      "Epoch 50/150\n",
      "66/66 [==============================] - 78s 1s/step - loss: 0.2064 - accuracy: 0.9150 - val_loss: 0.0260 - val_accuracy: 0.9189\n",
      "Epoch 51/150\n",
      "66/66 [==============================] - 78s 1s/step - loss: 0.1381 - accuracy: 0.9490 - val_loss: 3.6122e-04 - val_accuracy: 0.8735\n",
      "Epoch 52/150\n",
      "66/66 [==============================] - 81s 1s/step - loss: 0.1598 - accuracy: 0.9363 - val_loss: 2.9724e-05 - val_accuracy: 0.8768\n",
      "Epoch 53/150\n",
      "66/66 [==============================] - 91s 1s/step - loss: 0.1681 - accuracy: 0.9342 - val_loss: 0.0011 - val_accuracy: 0.8822\n",
      "Epoch 54/150\n",
      "66/66 [==============================] - 82s 1s/step - loss: 0.1512 - accuracy: 0.9454 - val_loss: 0.0240 - val_accuracy: 0.8778\n",
      "Epoch 55/150\n",
      "66/66 [==============================] - 78s 1s/step - loss: 0.1724 - accuracy: 0.9329 - val_loss: 0.4864 - val_accuracy: 0.8926\n",
      "Epoch 56/150\n",
      "66/66 [==============================] - 88s 1s/step - loss: 0.1523 - accuracy: 0.9411 - val_loss: 0.9072 - val_accuracy: 0.9103\n",
      "Epoch 57/150\n",
      "66/66 [==============================] - 78s 1s/step - loss: 0.1563 - accuracy: 0.9417 - val_loss: 0.5290 - val_accuracy: 0.9373\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 88s 1s/step - loss: 0.1480 - accuracy: 0.9426 - val_loss: 0.4588 - val_accuracy: 0.9243\n",
      "Epoch 59/150\n",
      "66/66 [==============================] - 77s 1s/step - loss: 0.1459 - accuracy: 0.9424 - val_loss: 0.0224 - val_accuracy: 0.8984\n",
      "Epoch 60/150\n",
      "66/66 [==============================] - 82s 1s/step - loss: 0.1526 - accuracy: 0.9384 - val_loss: 1.2353e-04 - val_accuracy: 0.8714\n",
      "Epoch 61/150\n",
      "66/66 [==============================] - 85s 1s/step - loss: 0.1603 - accuracy: 0.9346 - val_loss: 1.6364e-05 - val_accuracy: 0.8886\n",
      "Epoch 62/150\n",
      "66/66 [==============================] - 80s 1s/step - loss: 0.1408 - accuracy: 0.9455 - val_loss: 0.0019 - val_accuracy: 0.8908\n",
      "Epoch 63/150\n",
      "66/66 [==============================] - 82s 1s/step - loss: 0.1449 - accuracy: 0.9429 - val_loss: 0.0339 - val_accuracy: 0.8854\n",
      "Epoch 64/150\n",
      "66/66 [==============================] - 87s 1s/step - loss: 0.1358 - accuracy: 0.9496 - val_loss: 0.4239 - val_accuracy: 0.9053\n",
      "Epoch 65/150\n",
      "66/66 [==============================] - 86s 1s/step - loss: 0.1374 - accuracy: 0.9451 - val_loss: 0.6596 - val_accuracy: 0.9189\n",
      "Epoch 66/150\n",
      "66/66 [==============================] - 84s 1s/step - loss: 0.1458 - accuracy: 0.9439 - val_loss: 0.4795 - val_accuracy: 0.9373\n",
      "Epoch 67/150\n",
      "27/66 [===========>..................] - ETA: 35s - loss: 0.1045 - accuracy: 0.9606"
     ]
    }
   ],
   "source": [
    "# compile our model (this needs to be done after our setting our layers to being non-trainable\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "# train the head of the network for a few epochs (all other layers\n",
    "# are frozen) -- this will allow the new FC layers to start to become\n",
    "#initialized with actual \"learned\" values versus pure random\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit_generator(\n",
    "    trainGen,\n",
    "    steps_per_epoch=totalTrain // BATCH_SIZE,\n",
    "    validation_data=valGen,\n",
    "    validation_steps=totalVal // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weights)\n",
    "# reset the testing generator and evaluate the network after\n",
    "# fine-tuning just the network head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating after fine-tuning network head...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       576\n",
      "         1-3       1.00      0.38      0.55        50\n",
      "       10-12       0.90      0.94      0.92       105\n",
      "       13-15       0.83      0.66      0.73        29\n",
      "       20-25       0.81      0.95      0.88        41\n",
      "       30-40       0.88      0.98      0.93        46\n",
      "         4-5       0.62      0.92      0.74        66\n",
      "       41-56       1.00      0.93      0.96        14\n",
      "         6-9       1.00      0.74      0.85       101\n",
      "         60+       0.96      0.92      0.94        25\n",
      "\n",
      "    accuracy                           0.92      1053\n",
      "   macro avg       0.90      0.84      0.85      1053\n",
      "weighted avg       0.93      0.92      0.92      1053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating after fine-tuning network head...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "    steps=(totalTest // BATCH_SIZE) + 1)\n",
    "predIdxsClasses = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(testGen.classes, predIdxsClasses,\n",
    "    target_names=testGen.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1-3', '10-12', '13-15', '20-25', '30-40', '4-5', '41-56', '6-9', '60+']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs = testGen.class_indices.keys()\n",
    "PFRLabels = []\n",
    "for lab in labs:\n",
    "    PFRLabels.append(lab)\n",
    "PFRLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1-3</th>\n",
       "      <th>10-12</th>\n",
       "      <th>13-15</th>\n",
       "      <th>20-25</th>\n",
       "      <th>30-40</th>\n",
       "      <th>4-5</th>\n",
       "      <th>41-56</th>\n",
       "      <th>6-9</th>\n",
       "      <th>60+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1-3</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30-40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4-5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41-56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6-9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60+</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1-3  10-12  13-15  20-25  30-40  4-5  41-56  6-9  60+\n",
       "0      575    0      0      0      0      0    1      0    0    0\n",
       "1-3     10   32      0      0      1      0    7      0    0    0\n",
       "10-12    0    0     94      3      0      0    0      0    8    0\n",
       "13-15    1    0      3     22      0      3    0      0    0    0\n",
       "20-25    1    0      0      3     33      4    0      0    0    0\n",
       "30-40    0    0      0      0      0     43    0      0    0    3\n",
       "4-5      5    2      0      0      0      0   58      0    1    0\n",
       "41-56    0    0      0      0      0      3    0     11    0    0\n",
       "6-9      2    2      3      0      0      0   29      0   64    1\n",
       "60+      0    0      0      0      0      1    0      0    0   24"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(testGen.classes, predIdxsClasses)\n",
    "cm = pd.DataFrame(cm)\n",
    "cm.columns = PFRLabels\n",
    "cm.index = PFRLabels\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_PLOT_PATH = '../Models/PFRModel/train.png'\n",
    "plot_training(H, EPOCHS, WARMUP_PLOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('../Models/PFRModel/PFRModel.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
